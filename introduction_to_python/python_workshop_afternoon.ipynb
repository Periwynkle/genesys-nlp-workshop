{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Python for Digital Text Analysis (Part I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This session will provide an overview of the Python Natural Language Toolkit (NLTK) library (http://www.nltk.org).\n",
    "\n",
    "Workshop structure:\n",
    "\n",
    "1. Import necessary packages.\n",
    "2. Import four videos (comments only files).\n",
    "3. Tokenize each file.\n",
    "4. Type / token counts; lexical diversity.\n",
    "5. POS tagging\n",
    "6. Compute and visualise frequencies of most popular (proper) nouns, adjectives, verbs. Also frequencies of most popuar words overall...?\n",
    "7. Collocations\n",
    "8. N-grams\n",
    "\n",
    "*Open-Ended Exercises/Questions*\n",
    "What are the most common 3-grams, 4-grams..?\n",
    "Compare most frequent words (and types of words) in each of the four video comment datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK word tokenizer (ignores non-alpha characters) vs. tweet tokenizer (represents hashtags, @mentions, and emoji / doesn't strip them away). http://www.nltk.org/api/nltk.tokenize.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CommentTextDisplay\n",
      "no comments about rose???      i loovee her more than myself roseeeee \\u003c333333\n",
      "Sometimes when Lisa raps I forget that she's actually an adorable cinnamon roll\n",
      "BLACKPINK are the cutest \\u003c3\n",
      "l love BLACKPINK♡♡♡♡♡♡  (저 한국인임(\n",
      "Brazilian fan here giving support to BlackPink❤\n",
      "rose\n"
     ]
    }
   ],
   "source": [
    "#import os\n",
    "\n",
    "#for file in os.scandir('../data/kpop_videos_comments/blackpink'):\n",
    "#    print(file.path)\n",
    "    \n",
    "blackpink_filepath = '../data/kpop_videos_comments/blackpink/BLACKPINK_eng-ApzONNuuUGw_commentsOnly.txt'\n",
    "\n",
    "with open(blackpink_filepath, encoding=\"utf-8\") as text: # Need to use UTF 8 encoding to recognise emoji.\n",
    "    blackpink = text.read()\n",
    "    \n",
    "print(blackpink[:300]) # Print first 300 characters\n",
    "#print(blackpink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CommentTextDisplay\n",
      "no\n",
      "comments\n",
      "about\n",
      "rose\n",
      "?\n",
      "?\n",
      "?\n",
      "i\n",
      "loovee\n",
      "her\n",
      "more\n",
      "than\n",
      "myself\n",
      "roseeeee\n",
      "\\\n",
      "u003c333333\n",
      "Sometimes\n",
      "when\n",
      "Lisa\n",
      "raps\n",
      "I\n",
      "forget\n",
      "that\n",
      "she's\n",
      "actually\n",
      "an\n",
      "adorable\n",
      "cinnamon\n",
      "roll\n",
      "BLACKPINK\n",
      "are\n",
      "the\n",
      "cutest\n",
      "\\\n",
      "u003c3\n",
      "l\n",
      "love\n",
      "BLACKPINK\n",
      "♡\n",
      "♡\n",
      "♡\n",
      "(\n",
      "저\n",
      "한국인임\n",
      "(\n",
      "Brazilian\n",
      "fan\n",
      "here\n",
      "giving\n",
      "support\n",
      "to\n",
      "BlackPink\n",
      "❤\n",
      "rose\n"
     ]
    }
   ],
   "source": [
    "for word in TweetTokenizer().tokenize(blackpink[:300]):\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
